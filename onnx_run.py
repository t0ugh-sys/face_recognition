# -*- coding: utf-8 -*-
import cv2
import time
import numpy as np
import os
from deepface import DeepFace
import onnxruntime as ort
import logging
from PIL import Image
from torchvision import transforms
from scipy.special import softmax

# ===== é…ç½®å‚æ•° =====
DB_PATH = "face_db/"  # äººè„¸æ•°æ®åº“è·¯å¾„
MIN_CONFIDENCE = 0.3  # YOLOæ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼
RECOG_THRESH = 0.5  # äººè„¸è¯†åˆ«ä½™å¼¦ç›¸ä¼¼åº¦é˜ˆå€¼
MIN_FACE_SIZE = 40  # æœ€å°äººè„¸å°ºå¯¸(åƒç´ )
TARGET_FACE_SIZE = (224, 224)  # DeepFaceè¾“å…¥å°ºå¯¸
RESOLUTION = (640, 480)  # æ‘„åƒå¤´åˆ†è¾¨ç‡
EMOTION_THRESHOLD = 0.0  # æƒ…ç»ªç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆä¿æŒä¸º0ä»¥å¼ºåˆ¶æ˜¾ç¤ºï¼‰
YOLO_MODEL_PATH = "yolov8.onnx"  # YOLOv8 ONNXäººè„¸æ£€æµ‹æ¨¡å‹
EMOTION_MODEL_PATH = "minixception.onnx"  # MiniXception ONNXæ¨¡å‹è·¯å¾„
EMOTION_LABELS = ["Angry", "Disgust", "Fear", "Happy", "Normal", "Sad", "Surprise"]  # æƒ…ç»ªæ ‡ç­¾

# é…ç½®æ—¥å¿—
logging.basicConfig(
    filename='recognition.log',
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger()

# åˆ›å»ºæ•°æ®åº“ç›®å½•
os.makedirs(DB_PATH, exist_ok=True)

# é€‰æ‹©è®¾å¤‡
device = 'cuda' if ort.get_device() == 'GPU' else 'cpu'
print(f"âš™ï¸ ä½¿ç”¨è®¾å¤‡: {device}")
logger.info(f"Using device: {device}")

# ===== æ¨¡å‹åŠ è½½ =====
# 1. YOLOv8 ONNXäººè„¸æ£€æµ‹æ¨¡å‹
try:
    yolo_session = ort.InferenceSession(YOLO_MODEL_PATH, providers=['CUDAExecutionProvider' if device == 'cuda' else 'CPUExecutionProvider'])
    print("âœ… YOLOv8 ONNXäººè„¸æ£€æµ‹æ¨¡å‹åŠ è½½æˆåŠŸ")
    logger.info("YOLOv8 ONNX face detection model loaded")
except Exception as e:
    print(f"âŒ YOLOv8 ONNXåŠ è½½å¤±è´¥: {e}")
    logger.error(f"YOLOv8 ONNX load error: {e}")
    exit()

# 2. DeepFaceæ¨¡å‹ï¼ˆè½»é‡çº§SFaceï¼‰
try:
    DeepFace.build_model("SFace")
    print("âœ… DeepFace(SFace)æ¨¡å‹åŠ è½½æˆåŠŸ")
    logger.info("DeepFace SFace model built")
except Exception as e:
    print(f"âŒ DeepFaceåˆå§‹åŒ–å¤±è´¥: {e}")
    logger.error(f"DeepFace init error: {e}")
    exit()

# 3. MiniXception ONNXæƒ…ç»ªè¯†åˆ«æ¨¡å‹
try:
    emotion_session = ort.InferenceSession(EMOTION_MODEL_PATH, providers=['CUDAExecutionProvider' if device == 'cuda' else 'CPUExecutionProvider'])
    input_name = emotion_session.get_inputs()[0].name
    input_shape = emotion_session.get_inputs()[0].shape
    output_name = emotion_session.get_outputs()[0].name
    print(f"âœ… MiniXception ONNXæƒ…ç»ªæ¨¡å‹åŠ è½½æˆåŠŸ, è¾“å…¥: {input_name} å½¢çŠ¶: {input_shape}, è¾“å‡º: {output_name}")
    logger.info(f"MiniXception ONNX model loaded, input: {input_name}, shape: {input_shape}, output: {output_name}")
except Exception as e:
    print(f"âŒ MiniXception ONNXåŠ è½½å¤±è´¥: {e}")
    logger.error(f"MiniXception ONNX load error: {e}")
    exit()

# ===== å‘é‡æ•°æ®åº“ =====
database = {}  # æ ¼å¼: {äººå: [åµŒå…¥å‘é‡åˆ—è¡¨]}

def init_vector_db():
    """ä»æ–‡ä»¶åŠ è½½é¢„å­˜åµŒå…¥å‘é‡"""
    global database
    if os.path.exists(f"{DB_PATH}/embeddings.npy"):
        database = np.load(f"{DB_PATH}/embeddings.npy", allow_pickle=True).item()
        print(f"âœ… åŠ è½½{len(database)}ä¸ªäººçš„åµŒå…¥å‘é‡")
        logger.info(f"Loaded {len(database)} embeddings")
    else:
        print("â„¹ï¸ æœªæ‰¾åˆ°é¢„å­˜æ•°æ®åº“ï¼Œå°†ä»é›¶åˆ›å»º")
        logger.info("No existing DB found")

def cosine_similarity(vec_a, vec_b):
    """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆNumPyå®ç°ï¼‰"""
    norm_a = np.linalg.norm(vec_a)
    norm_b = np.linalg.norm(vec_b)
    if norm_a == 0 or norm_b == 0:
        return 0
    return np.dot(vec_a, vec_b) / (norm_a * norm_b)

# ===== æ ¸å¿ƒå‡½æ•° =====
transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),
    transforms.Resize((96 ,96)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])
])

def preprocess_yolo_input(frame, img_size=640):
    """é¢„å¤„ç†YOLOv8 ONNXè¾“å…¥"""
    img = cv2.resize(frame, (img_size, img_size))
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = img.transpose((2, 0, 1)).astype(np.float32) / 255.0
    img = np.expand_dims(img, axis=0)
    return img

def postprocess_yolo_output(outputs, img_shape, conf_thres=0.3, iou_thres=0.45):
    """å¤„ç†YOLOv8 ONNXè¾“å‡ºï¼ˆå‡è®¾è¾“å‡ºä¸º[1, 5, 8400]ï¼‰ï¼Œæ·»åŠ NMS"""
    boxes = []
    scores = []
    output = outputs[0]  # [1, 5, 8400]
    output = output.transpose((0, 2, 1))  # [1, 8400, 5]
    output = output[0]  # [8400, 5]
    for det in output:
        conf = det[4]
        if conf < conf_thres:
            continue
        x_center, y_center, w, h = det[:4]
        x1 = int((x_center - w / 2) * img_shape[1] / 640)
        y1 = int((y_center - h / 2) * img_shape[0] / 640)
        x2 = int((x_center + w / 2) * img_shape[1] / 640)
        y2 = int((y_center + h / 2) * img_shape[0] / 640)
        boxes.append([x1, y1, x2, y2])
        scores.append(conf)

    boxes = np.array(boxes)
    scores = np.array(scores)

    if len(boxes) > 0:
        # åº”ç”¨NMS
        indices = cv2.dnn.NMSBoxes(boxes.tolist(), scores.tolist(), conf_thres, iou_thres)
        if len(indices) > 0:
            return [boxes[i] for i in indices]
    return boxes

def get_face_embedding(face_img: np.ndarray) -> np.ndarray:
    """æå–äººè„¸åµŒå…¥å‘é‡ï¼ˆä½¿ç”¨DeepFaceï¼‰"""
    try:
        face_rgb = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)
        face_rgb = cv2.resize(face_rgb, TARGET_FACE_SIZE)
        embedding = DeepFace.represent(
            img_path=face_rgb,
            model_name="SFace",
            detector_backend="skip",
            enforce_detection=False
        )[0]["embedding"]
        return np.array(embedding, dtype=np.float32) # æ¯ä¸ªäººè„¸å¯¹åº”128çš„å‘é‡
    except Exception as e:
        logger.error(f"ç‰¹å¾æå–å¤±è´¥: {str(e)}")
        return np.zeros(128, dtype=np.float32)  # è¿”å›ç©ºå‘é‡

def recognize_face(face_img: np.ndarray):
    """åŸºäºä½™å¼¦ç›¸ä¼¼åº¦è¯†åˆ«äººè„¸"""
    try:
        query_emb = get_face_embedding(face_img)
        best_match = ("Unknown", 0.0)

        # éå†æ•°æ®åº“æ‰€æœ‰äººå‘˜
        for name, emb_list in database.items():
            for stored_emb in emb_list:
                similarity = cosine_similarity(query_emb, stored_emb)
                if similarity > best_match[1]:
                    best_match = (name, similarity)

        # åŠ¨æ€é˜ˆå€¼è°ƒæ•´ï¼ˆå¤§è„¸æ›´ä¸¥æ ¼ï¼‰
        face_area = face_img.shape[0] * face_img.shape[1]
        dynamic_thresh = max(0.25, RECOG_THRESH - 0.05 * (face_area / 10000))

        return best_match if best_match[1] > dynamic_thresh else ("Unknown", 0.0)
    except Exception as e:
        logger.error(f"è¯†åˆ«å¼‚å¸¸: {str(e)}")
        return "Error", 0.0

def detect_emotion(face_img: np.ndarray):
    """ä½¿ç”¨MiniXception ONNXæ£€æµ‹æƒ…ç»ª"""
    try:
        if face_img.size == 0 or face_img.shape[0] < 10:
            return "Unknown", 0.0

        face_pil = Image.fromarray(cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB))
        face_tensor = transform(face_pil).numpy()
        face_tensor = np.expand_dims(face_tensor, axis=0)  # [1, 1, 96, 96]
        input_name = emotion_session.get_inputs()[0].name
        inputs = {input_name: face_tensor}

        outputs = emotion_session.run(None, inputs)
        if not outputs or len(outputs) == 0:
            raise ValueError("ONNXæ¨¡å‹è¾“å‡ºä¸ºç©º")
        probs = softmax(outputs[0], axis=1)[0]  # å‡è®¾ç¬¬ä¸€ä¸ªè¾“å‡ºæ˜¯logits
        conf = np.max(probs)
        idx = np.argmax(probs)

        emotion = EMOTION_LABELS[idx] if 0 <= idx < len(EMOTION_LABELS) else "Unknown"
        confidence = conf
        logger.info(f"Emotion detection: {emotion}, confidence: {confidence}, probs: {probs}")
        return emotion, confidence
    except Exception as e:
        logger.error(f"æƒ…ç»ªæ£€æµ‹å¼‚å¸¸: {str(e)}")
        return "Error", 0.0

def enroll_face(face_img: np.ndarray, name: str):
    """æ³¨å†Œäººè„¸åˆ°æ•°æ®åº“"""
    try:
        embedding = get_face_embedding(face_img)

        # æ·»åŠ åˆ°æ•°æ®åº“
        if name not in database:
            database[name] = []
        database[name].append(embedding)

        # æŒä¹…åŒ–å­˜å‚¨
        np.save(f"{DB_PATH}/embeddings.npy", database)
        print(f"âœ… {name} æ³¨å†ŒæˆåŠŸ (æ€»æ ·æœ¬: {len(database[name])})")
        logger.info(f"Enrolled: {name} (samples: {len(database[name])})")
    except Exception as e:
        print(f"âŒ æ³¨å†Œå¤±è´¥: {e}")
        logger.error(f"Enrollment failed: {e}")

# ===== ä¸»ç¨‹åº =====
def main():
    init_vector_db()  # åˆå§‹åŒ–æ•°æ®åº“
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ æ‘„åƒå¤´åˆå§‹åŒ–å¤±è´¥")
        logger.error("Camera init failed")
        exit()
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, RESOLUTION[0])
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, RESOLUTION[1])

    fps_counter = []
    prev_time = time.time()

    print("\nã€æ“ä½œè¯´æ˜ã€‘")
    print("- æŒ‰ 'Q': é€€å‡ºç¨‹åº")
    print("- æŒ‰ 'E': æ³¨å†Œå½“å‰é€‰ä¸­äººè„¸ï¼ˆéœ€è¾“å…¥å§“åï¼‰")
    print("- ç»¿è‰²æ¡†: å·²çŸ¥èº«ä»½ | çº¢è‰²æ¡†: æœªçŸ¥èº«ä»½ | é’è‰²æ–‡å­—: æƒ…ç»ªçŠ¶æ€")

    while True:
        ret, frame = cap.read()
        if not ret:
            logger.warning("å¸§è¯»å–å¤±è´¥")
            continue

        # è®¡ç®—FPS
        curr_time = time.time()
        fps = 1 / (curr_time - prev_time)
        fps_counter.append(fps)
        avg_fps = np.mean(fps_counter[-10:]) if fps_counter else 0
        prev_time = curr_time

        # YOLOv8 ONNXäººè„¸æ£€æµ‹
        input_tensor = preprocess_yolo_input(frame)
        outputs = yolo_session.run(None, {yolo_session.get_inputs()[0].name: input_tensor})
        boxes = postprocess_yolo_output(outputs, frame.shape, MIN_CONFIDENCE, iou_thres=0.45)

        # è¿‡æ»¤æ— æ•ˆæ£€æµ‹æ¡†
        valid_boxes = []
        for box in boxes:
            x1, y1, x2, y2 = map(int, box)
            w, h = x2 - x1, y2 - y1
            if (0.7 < w / h < 1.4 and  # å®½é«˜æ¯”åˆç†
                    w > MIN_FACE_SIZE and  # æœ€å°å®½åº¦
                    h > MIN_FACE_SIZE):  # æœ€å°é«˜åº¦
                valid_boxes.append(box)

        # å¤„ç†æ¯ä¸ªæ£€æµ‹åˆ°çš„äººè„¸
        display_frame = frame.copy()
        for box in valid_boxes:
            x1, y1, x2, y2 = map(int, box)

            # è¾¹ç•Œæ£€æŸ¥
            x1, y1 = max(0, x1), max(0, y1)
            x2, y2 = min(frame.shape[1] - 1, x2), min(frame.shape[0] - 1, y2)

            # æå–äººè„¸åŒºåŸŸ
            face_img = frame[y1:y2, x1:x2]
            if face_img.size == 0:  # è·³è¿‡ç©ºå›¾åƒ
                continue

            # åŒæ­¥å¤„ç†è¯†åˆ«å’Œæƒ…ç»ªæ£€æµ‹
            identity, conf = recognize_face(face_img)
            emotion, emo_conf = detect_emotion(face_img)

            # ç»˜åˆ¶ç»“æœ
            color = (0, 255, 0) if identity != "Unknown" else (0, 0, 255)
            cv2.rectangle(display_frame, (x1, y1), (x2, y2), color, 2)

            # èº«ä»½æ ‡ç­¾ï¼ˆæ˜¾ç¤ºåœ¨ä¸Šæ–¹ï¼‰
            id_text = f"{identity[:12]}:{conf:.0%}" if identity != "Unknown" else "Unknown"
            cv2.putText(display_frame, id_text, (x1, y1 - 25 if y1 - 25 > 0 else y1 + 5),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)

            # æƒ…ç»ªæ ‡ç­¾ï¼ˆæ˜¾ç¤ºåœ¨ä¸‹æ–¹ï¼‰
            if emo_conf >= 0:  # å¼ºåˆ¶æ˜¾ç¤ºæƒ…ç»ª
                emo_text = f"{emotion[:8]}:{emo_conf:.0%}"
                cv2.putText(display_frame, emo_text, (x1, y2 + 20 if y2 + 20 < frame.shape[0] else y2 - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)

        # æ˜¾ç¤ºå¸§ç‡
        cv2.putText(display_frame, f"FPS: {int(avg_fps)}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        cv2.imshow("Multi-Face Recognition System", display_frame)

        # æŒ‰é”®å¤„ç†
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        elif key == ord('e') and valid_boxes:
            # é€‰æ‹©æœ€å¤§äººè„¸æ³¨å†Œ
            largest_idx = np.argmax([(box[2] - box[0]) * (box[3] - box[1]) for box in valid_boxes])
            x1, y1, x2, y2 = map(int, valid_boxes[largest_idx])
            face_img = frame[y1:y2, x1:x2]
            name = input("è¯·è¾“å…¥æ³¨å†Œå§“å: ").strip()
            if name:
                enroll_face(face_img, name)

    # é‡Šæ”¾èµ„æº
    cap.release()
    cv2.destroyAllWindows()
    print("âœ… ç³»ç»Ÿæ­£å¸¸é€€å‡º")
    logger.info("System shutdown")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt as e:
        print("ğŸ”Œ ç³»ç»Ÿæ­£å¸¸é€€å‡º")
        logger.info("System shutdown")